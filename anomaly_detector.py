# anomaly_detector.py - Zaawansowany system detekcji anomalii na RTG
"""
System detekcji anomalii poprzez por√≥wnywanie obraz√≥w RTG:
1. Znajduje najbardziej podobny obraz wzorcowy (czysty)
2. Wyr√≥wnuje obrazy (image alignment)
3. Oblicza r√≥≈ºnice i wykrywa anomalie
4. Generuje szczeg√≥≈Çowy raport z wizualizacjƒÖ
"""

import os
import cv2
import numpy as np
from pathlib import Path
from typing import List, Tuple, Dict, Optional
import json
from datetime import datetime
from scipy import ndimage
from skimage.metrics import structural_similarity as ssim
from skimage.feature import match_template
import pickle


class ImageMatcher:
    """Znajduje najbardziej podobny obraz wzorcowy"""
    
    def __init__(self, reference_dir: str):
        """
        Args:
            reference_dir: Katalog z obrazami wzorcowymi (czystymi)
        """
        self.reference_dir = Path(reference_dir)
        self.reference_images = []
        self.reference_features = []
        self._load_references()
    
    def _load_references(self):
        """≈Åaduje wszystkie obrazy wzorcowe"""
        print(f"üìÅ ≈Åadowanie obraz√≥w wzorcowych z: {self.reference_dir}")
        
        for root, dirs, files in os.walk(self.reference_dir):
            for file in files:
                if file.endswith('.bmp') and 'czarno' not in file.lower():
                    img_path = Path(root) / file
                    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
                    if img is not None:
                        # Oblicz features dla szybszego dopasowywania
                        features = self._extract_features(img)
                        self.reference_images.append({
                            'path': img_path,
                            'image': img,
                            'features': features
                        })
        
        print(f"‚úÖ Za≈Çadowano {len(self.reference_images)} obraz√≥w wzorcowych")
    
    def _extract_features(self, img: np.ndarray) -> Dict:
        """Wyodrƒôbnia cechy obrazu do por√≥wnywania"""
        # Zmniejsz dla szybszego przetwarzania
        small = cv2.resize(img, (256, 256))
        
        # Histogram
        hist = cv2.calcHist([small], [0], None, [64], [0, 256])
        hist = cv2.normalize(hist, hist).flatten()
        
        # Gradient magnitude (krawƒôdzie)
        sobelx = cv2.Sobel(small, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(small, cv2.CV_64F, 0, 1, ksize=3)
        gradient_mag = np.sqrt(sobelx**2 + sobely**2)
        
        # Momenty obrazu
        moments = cv2.moments(small)
        
        return {
            'histogram': hist,
            'gradient_mean': np.mean(gradient_mag),
            'gradient_std': np.std(gradient_mag),
            'intensity_mean': np.mean(small),
            'intensity_std': np.std(small),
            'moments': moments
        }
    
    def _compare_features(self, features1: Dict, features2: Dict) -> float:
        """Por√≥wnuje cechy dw√≥ch obraz√≥w, zwraca podobie≈Ñstwo [0-1]"""
        # Histogram correlation
        hist_corr = cv2.compareHist(
            features1['histogram'], 
            features2['histogram'], 
            cv2.HISTCMP_CORREL
        )
        
        # Statystyki gradientu
        grad_diff = abs(features1['gradient_mean'] - features2['gradient_mean'])
        grad_diff_norm = 1 - min(grad_diff / 255.0, 1.0)
        
        # Statystyki intensywno≈õci
        int_diff = abs(features1['intensity_mean'] - features2['intensity_mean'])
        int_diff_norm = 1 - min(int_diff / 255.0, 1.0)
        
        # ≈ÅƒÖczone podobie≈Ñstwo (wa≈ºona ≈õrednia)
        similarity = (
            0.5 * hist_corr +
            0.25 * grad_diff_norm +
            0.25 * int_diff_norm
        )
        
        return max(0, min(1, similarity))
    
    def find_best_match(self, query_img: np.ndarray, top_k: int = 5) -> List[Dict]:
        """
        Znajd≈∫ najbardziej podobne obrazy wzorcowe
        
        Args:
            query_img: Obraz do dopasowania
            top_k: Ile najlepszych dopasowa≈Ñ zwr√≥ciƒá
            
        Returns:
            Lista s≈Çownik√≥w z informacjami o dopasowaniach
        """
        query_features = self._extract_features(query_img)
        
        matches = []
        for ref in self.reference_images:
            similarity = self._compare_features(query_features, ref['features'])
            matches.append({
                'path': ref['path'],
                'image': ref['image'],
                'similarity': similarity
            })
        
        # Sortuj po podobie≈Ñstwie
        matches.sort(key=lambda x: x['similarity'], reverse=True)
        
        return matches[:top_k]


class ImageAligner:
    """Wyr√≥wnuje dwa obrazy dla dok≈Çadnego por√≥wnania"""
    
    @staticmethod
    def align_images(reference: np.ndarray, image: np.ndarray, 
                     method: str = 'ecc') -> Tuple[np.ndarray, np.ndarray]:
        """
        Wyr√≥wnuje obraz do referencji
        
        Args:
            reference: Obraz wzorcowy
            image: Obraz do wyr√≥wnania
            method: 'ecc' lub 'feature' (Enhanced Correlation Coefficient)
            
        Returns:
            (aligned_image, transformation_matrix)
        """
        # Upewnij siƒô, ≈ºe obrazy majƒÖ ten sam rozmiar
        if reference.shape != image.shape:
            image = cv2.resize(image, (reference.shape[1], reference.shape[0]))
        
        if method == 'ecc':
            return ImageAligner._align_ecc(reference, image)
        else:
            return ImageAligner._align_feature(reference, image)
    
    @staticmethod
    def _align_ecc(reference: np.ndarray, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Wyr√≥wnanie ECC (Enhanced Correlation Coefficient)"""
        # Konwertuj do float32
        ref_gray = reference.astype(np.float32)
        img_gray = image.astype(np.float32)
        
        # Zdefiniuj typ transformacji (affine)
        warp_mode = cv2.MOTION_AFFINE
        warp_matrix = np.eye(2, 3, dtype=np.float32)
        
        # Kryteria zako≈Ñczenia
        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-6)
        
        try:
            # Wyr√≥wnaj obrazy
            _, warp_matrix = cv2.findTransformECC(
                ref_gray, img_gray, warp_matrix, warp_mode, criteria, 
                inputMask=None, gaussFiltSize=5
            )
            
            # Zastosuj transformacjƒô
            aligned = cv2.warpAffine(
                image, warp_matrix, (reference.shape[1], reference.shape[0]),
                flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP
            )
            
            return aligned, warp_matrix
            
        except Exception as e:
            print(f"‚ö†Ô∏è Wyr√≥wnanie ECC nie powiod≈Ço siƒô: {e}, zwracam oryginalny obraz")
            return image, np.eye(2, 3, dtype=np.float32)
    
    @staticmethod
    def _align_feature(reference: np.ndarray, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Wyr√≥wnanie oparte na cechach (ORB)"""
        # Wykryj punkty kluczowe i deskryptory
        orb = cv2.ORB_create(5000)
        kp1, des1 = orb.detectAndCompute(reference, None)
        kp2, des2 = orb.detectAndCompute(image, None)
        
        if des1 is None or des2 is None:
            return image, np.eye(2, 3, dtype=np.float32)
        
        # Dopasuj cechy
        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
        matches = matcher.knnMatch(des1, des2, k=2)
        
        # Filtruj dobre dopasowania (Lowe's ratio test)
        good_matches = []
        for match_pair in matches:
            if len(match_pair) == 2:
                m, n = match_pair
                if m.distance < 0.75 * n.distance:
                    good_matches.append(m)
        
        if len(good_matches) < 10:
            return image, np.eye(2, 3, dtype=np.float32)
        
        # Wyodrƒôbnij punkty
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        
        # Znajd≈∫ transformacjƒô afinicznƒÖ
        warp_matrix, inliers = cv2.estimateAffinePartial2D(dst_pts, src_pts)
        
        if warp_matrix is None:
            return image, np.eye(2, 3, dtype=np.float32)
        
        # Zastosuj transformacjƒô
        aligned = cv2.warpAffine(
            image, warp_matrix, (reference.shape[1], reference.shape[0])
        )
        
        return aligned, warp_matrix


class AnomalyDetector:
    """Wykrywa anomalie przez por√≥wnanie obraz√≥w"""
    
    def __init__(self, threshold: float = 25, min_area: int = 300, max_area: int = 50000):
        """
        Args:
            threshold: Pr√≥g r√≥≈ºnicy pikseli
            min_area: Minimalna powierzchnia anomalii (piksele)
            max_area: Maksymalna powierzchnia anomalii (piksele)
        """
        self.threshold = threshold
        self.min_area = min_area
        self.max_area = max_area
    
    def detect_anomalies(self, reference: np.ndarray, image: np.ndarray,
                        use_ssim: bool = True) -> Dict:
        """
        Wykryj anomalie por√≥wnujƒÖc dwa obrazy
        
        Args:
            reference: Obraz wzorcowy (czysty)
            image: Obraz do sprawdzenia
            use_ssim: Czy u≈ºyƒá SSIM zamiast prostej r√≥≈ºnicy
            
        Returns:
            S≈Çownik z wynikami detekcji
        """
        # Upewnij siƒô, ≈ºe obrazy majƒÖ ten sam rozmiar
        if reference.shape != image.shape:
            image = cv2.resize(image, (reference.shape[1], reference.shape[0]))
        
        # Wstƒôpne przetwarzanie
        ref_processed = self._preprocess(reference)
        img_processed = self._preprocess(image)
        
        if use_ssim:
            # SSIM - lepiej radzi sobie z niewielkimi r√≥≈ºnicami w jasno≈õci
            score, diff_map = ssim(ref_processed, img_processed, full=True)
            diff_map = (1 - diff_map) * 255
            diff_map = diff_map.astype(np.uint8)
        else:
            # Prosta r√≥≈ºnica bezwzglƒôdna
            diff_map = cv2.absdiff(ref_processed, img_processed)
        
        # Wykryj anomalie
        anomalies = self._find_anomalies(diff_map)
        
        return {
            'difference_map': diff_map,
            'anomalies': anomalies,
            'anomaly_count': len(anomalies),
            'has_anomaly': len(anomalies) > 0,
            'ssim_score': score if use_ssim else None
        }
    
    def _preprocess(self, img: np.ndarray) -> np.ndarray:
        """Wstƒôpne przetwarzanie obrazu"""
        # Histogram equalization dla lepszego kontrastu
        img_eq = cv2.equalizeHist(img)
        
        # Denoising
        img_denoised = cv2.fastNlMeansDenoising(img_eq, h=10)
        
        return img_denoised
    
    def _find_anomalies(self, diff_map: np.ndarray) -> List[Dict]:
        """Znajd≈∫ regiony anomalii na mapie r√≥≈ºnic"""
        # Progowanie
        _, binary = cv2.threshold(diff_map, self.threshold, 255, cv2.THRESH_BINARY)
        
        # Operacje morfologiczne
        kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))
        
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_open, iterations=2)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_close, iterations=2)
        
        # Znajd≈∫ kontury
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        anomalies = []
        for contour in contours:
            area = cv2.contourArea(contour)
            
            # Filtruj po obszarze
            if area < self.min_area or area > self.max_area:
                continue
            
            # Bounding box
            x, y, w, h = cv2.boundingRect(contour)
            
            # Filtruj po kszta≈Çcie (aspect ratio)
            aspect_ratio = w / h if h > 0 else 0
            if aspect_ratio > 10 or aspect_ratio < 0.1:
                continue
            
            # Solidno≈õƒá (solidity)
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = area / hull_area if hull_area > 0 else 0
            
            if solidity < 0.3:  # Zbyt nieregularne
                continue
            
            anomalies.append({
                'bbox': (x, y, w, h),
                'area': area,
                'solidity': solidity,
                'aspect_ratio': aspect_ratio,
                'contour': contour
            })
        
        return anomalies


class AnomalyReportGenerator:
    """Generuje raporty z wykrytymi anomaliami"""
    
    @staticmethod
    def generate_report(original_img: np.ndarray, reference_img: np.ndarray,
                       aligned_img: np.ndarray, detection_result: Dict,
                       output_path: str, metadata: Dict = None) -> str:
        """
        Generuje kompletny raport wizualny
        
        Args:
            original_img: Oryginalny obraz do sprawdzenia
            reference_img: Dopasowany obraz wzorcowy
            aligned_img: Wyr√≥wnany obraz
            detection_result: Wyniki detekcji
            output_path: ≈öcie≈ºka do zapisu raportu
            metadata: Dodatkowe metadane
            
        Returns:
            ≈öcie≈ºka do wygenerowanego raportu
        """
        # Przygotuj wizualizacje
        annotated = AnomalyReportGenerator._draw_anomalies(
            original_img, detection_result['anomalies']
        )
        diff_colored = AnomalyReportGenerator._colorize_diff(
            detection_result['difference_map']
        )
        
        # Utw√≥rz grid z wizualizacjami
        report_img = AnomalyReportGenerator._create_report_grid(
            original_img, reference_img, aligned_img,
            diff_colored, annotated, detection_result
        )
        
        # Zapisz raport obrazowy
        cv2.imwrite(output_path, report_img)
        
        # Generuj raport JSON
        json_path = output_path.rsplit('.', 1)[0] + '_report.json'
        AnomalyReportGenerator._save_json_report(
            json_path, detection_result, metadata
        )
        
        return output_path
    
    @staticmethod
    def _draw_anomalies(img: np.ndarray, anomalies: List[Dict]) -> np.ndarray:
        """Rysuje wykryte anomalie na obrazie"""
        # Konwertuj do BGR dla kolorowych adnotacji
        if len(img.shape) == 2:
            annotated = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        else:
            annotated = img.copy()
        
        for i, anomaly in enumerate(anomalies):
            x, y, w, h = anomaly['bbox']
            
            # Rysuj prostokƒÖt - zawsze czerwony
            cv2.rectangle(annotated, (x, y), (x+w, y+h), (0, 0, 255), 3)
            
            # Rysuj markery w rogach - tak≈ºe czerwone (wszystkie rogi)
            corner_size = 15
            # Lewy g√≥rny r√≥g
            cv2.line(annotated, (x, y), (x + corner_size, y), (0, 0, 255), 4)
            cv2.line(annotated, (x, y), (x, y + corner_size), (0, 0, 255), 4)
            # Prawy g√≥rny r√≥g
            cv2.line(annotated, (x+w, y), (x+w - corner_size, y), (0, 0, 255), 4)
            cv2.line(annotated, (x+w, y), (x+w, y + corner_size), (0, 0, 255), 4)
            # Lewy dolny r√≥g
            cv2.line(annotated, (x, y+h), (x + corner_size, y+h), (0, 0, 255), 4)
            cv2.line(annotated, (x, y+h), (x, y+h - corner_size), (0, 0, 255), 4)
            # Prawy dolny r√≥g
            cv2.line(annotated, (x+w, y+h), (x+w - corner_size, y+h), (0, 0, 255), 4)
            cv2.line(annotated, (x+w, y+h), (x+w, y+h - corner_size), (0, 0, 255), 4)
            
            # Etykieta - czerwone t≈Ço, bia≈Çy tekst
            label = f"A{i+1}: {anomaly['area']:.0f}px"
            cv2.putText(annotated, label, (x, y-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        return annotated
    
    @staticmethod
    def _colorize_diff(diff_map: np.ndarray) -> np.ndarray:
        """Koloruje mapƒô r√≥≈ºnic dla lepszej wizualizacji"""
        # Normalizuj do 0-255
        diff_normalized = cv2.normalize(diff_map, None, 0, 255, cv2.NORM_MINMAX)
        
        # Zastosuj kolorowƒÖ mapƒô (heatmap)
        colored = cv2.applyColorMap(diff_normalized.astype(np.uint8), cv2.COLORMAP_JET)
        
        return colored
    
    @staticmethod
    def _create_report_grid(original: np.ndarray, reference: np.ndarray,
                           aligned: np.ndarray, diff_colored: np.ndarray,
                           annotated: np.ndarray, detection_result: Dict) -> np.ndarray:
        """Tworzy grid z wszystkimi wizualizacjami"""
        # Konwertuj grayscale do BGR je≈õli potrzeba
        def to_bgr(img):
            if len(img.shape) == 2:
                return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
            return img
        
        original = to_bgr(original)
        reference = to_bgr(reference)
        aligned = to_bgr(aligned)
        annotated = to_bgr(annotated)
        
        # Upewnij siƒô, ≈ºe wszystkie majƒÖ ten sam rozmiar
        h, w = original.shape[:2]
        reference = cv2.resize(reference, (w, h))
        aligned = cv2.resize(aligned, (w, h))
        diff_colored = cv2.resize(diff_colored, (w, h))
        annotated = cv2.resize(annotated, (w, h))
        
        # Dodaj etykiety
        def add_label(img, text, color=(255, 255, 255)):
            labeled = img.copy()
            cv2.rectangle(labeled, (0, 0), (w, 50), (0, 0, 0), -1)
            cv2.putText(labeled, text, (10, 35),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)
            return labeled
        
        original = add_label(original, "Obraz testowy")
        reference = add_label(reference, "Obraz wzorcowy")
        aligned = add_label(aligned, "Wyrownany")
        diff_colored = add_label(diff_colored, "Mapa roznic (heatmap)")
        annotated = add_label(annotated, f"Wykryte anomalie: {len(detection_result['anomalies'])}", 
                            (0, 255, 0) if detection_result['has_anomaly'] else (255, 255, 255))
        
        # Grid 2x3
        row1 = np.hstack([original, reference, aligned])
        row2 = np.hstack([diff_colored, annotated, annotated])  # Duplikuj ostatni dla symetrii
        
        grid = np.vstack([row1, row2])
        
        # Dodaj podsumowanie na dole
        summary_height = 100
        summary = np.zeros((summary_height, grid.shape[1], 3), dtype=np.uint8)
        
        anomaly_count = len(detection_result['anomalies'])
        status = "ANOMALIA WYKRYTA!" if detection_result['has_anomaly'] else "BRAK ANOMALII"
        status_color = (0, 0, 255) if detection_result['has_anomaly'] else (0, 255, 0)
        
        cv2.putText(summary, status, (20, 40),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, status_color, 3)
        cv2.putText(summary, f"Liczba anomalii: {anomaly_count}", (20, 80),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        
        if detection_result.get('ssim_score') is not None:
            cv2.putText(summary, f"SSIM: {detection_result['ssim_score']:.4f}", 
                       (grid.shape[1] - 300, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        
        final = np.vstack([grid, summary])
        
        return final
    
    @staticmethod
    def _save_json_report(json_path: str, detection_result: Dict, metadata: Dict = None):
        """Zapisuje raport w formacie JSON"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'has_anomaly': detection_result['has_anomaly'],
            'anomaly_count': detection_result['anomaly_count'],
            'ssim_score': detection_result.get('ssim_score'),
            'anomalies': []
        }
        
        for i, anomaly in enumerate(detection_result['anomalies']):
            report['anomalies'].append({
                'id': i + 1,
                'bbox': anomaly['bbox'],
                'area': float(anomaly['area']),
                'solidity': float(anomaly['solidity']),
                'aspect_ratio': float(anomaly['aspect_ratio'])
            })
        
        if metadata:
            report['metadata'] = metadata
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)


class RTGAnomalySystem:
    """G≈Ç√≥wny system detekcji anomalii RTG"""
    
    def __init__(self, reference_dir: str, output_dir: str = 'anomaly_reports'):
        """
        Args:
            reference_dir: Katalog z obrazami wzorcowymi (czystymi)
            output_dir: Katalog do zapisywania raport√≥w
        """
        self.matcher = ImageMatcher(reference_dir)
        self.aligner = ImageAligner()
        self.detector = AnomalyDetector()
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        print(f"üöÄ System detekcji anomalii RTG zainicjalizowany")
        print(f"üìÇ Obrazy wzorcowe: {reference_dir}")
        print(f"üìÇ Raporty: {output_dir}")
    
    def process_image(self, image_path: str, use_alignment: bool = True,
                     use_ssim: bool = True, save_report: bool = True) -> Dict:
        """
        Przetw√≥rz obraz i wykryj anomalie
        
        Args:
            image_path: ≈öcie≈ºka do obrazu do sprawdzenia
            use_alignment: Czy wyr√≥wnywaƒá obrazy
            use_ssim: Czy u≈ºyƒá SSIM
            save_report: Czy zapisaƒá raport
            
        Returns:
            S≈Çownik z wynikami analizy
        """
        print(f"\nüîç Przetwarzanie: {image_path}")
        
        # Wczytaj obraz
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise ValueError(f"Nie mo≈ºna wczytaƒá obrazu: {image_path}")
        
        # Znajd≈∫ najbardziej podobny obraz wzorcowy
        print("üîé Szukanie najbardziej podobnego obrazu wzorcowego...")
        matches = self.matcher.find_best_match(img, top_k=1)
        
        if not matches:
            raise ValueError("Nie znaleziono obraz√≥w wzorcowych")
        
        best_match = matches[0]
        reference_img = best_match['image']
        similarity = best_match['similarity']
        
        print(f"‚úÖ Znaleziono dopasowanie: {best_match['path'].name}")
        print(f"   Podobie≈Ñstwo: {similarity:.2%}")
        
        # Wyr√≥wnaj obrazy
        if use_alignment:
            print("‚öôÔ∏è Wyr√≥wnywanie obraz√≥w...")
            aligned_img, transform = self.aligner.align_images(reference_img, img)
        else:
            aligned_img = cv2.resize(img, (reference_img.shape[1], reference_img.shape[0]))
            transform = None
        
        # Wykryj anomalie
        print("üî¨ Wykrywanie anomalii...")
        detection_result = self.detector.detect_anomalies(
            reference_img, aligned_img, use_ssim=use_ssim
        )
        
        print(f"{'‚ùå' if detection_result['has_anomaly'] else '‚úÖ'} "
              f"Wykryto {detection_result['anomaly_count']} anomalii")
        
        # Generuj raport
        if save_report:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            img_name = Path(image_path).stem
            report_path = self.output_dir / f"report_{img_name}_{timestamp}.png"
            
            print(f"üìä Generowanie raportu...")
            AnomalyReportGenerator.generate_report(
                img, reference_img, aligned_img, detection_result,
                str(report_path),
                metadata={
                    'input_image': image_path,
                    'reference_image': str(best_match['path']),
                    'similarity': similarity,
                    'alignment_used': use_alignment,
                    'ssim_used': use_ssim
                }
            )
            print(f"üíæ Raport zapisany: {report_path}")
        
        return {
            'has_anomaly': detection_result['has_anomaly'],
            'anomaly_count': detection_result['anomaly_count'],
            'anomalies': detection_result['anomalies'],
            'reference_match': str(best_match['path']),
            'similarity': similarity,
            'ssim_score': detection_result.get('ssim_score'),
            'report_path': str(report_path) if save_report else None
        }
    
    def batch_process(self, image_dir: str, pattern: str = '*.bmp') -> List[Dict]:
        """
        Przetwarzaj wiele obraz√≥w w partii
        
        Args:
            image_dir: Katalog z obrazami do sprawdzenia
            pattern: Wzorzec nazw plik√≥w
            
        Returns:
            Lista wynik√≥w dla ka≈ºdego obrazu
        """
        image_paths = list(Path(image_dir).rglob(pattern))
        print(f"\nüì¶ Przetwarzanie partiami: {len(image_paths)} obraz√≥w")
        
        results = []
        for img_path in image_paths:
            try:
                result = self.process_image(str(img_path))
                results.append(result)
            except Exception as e:
                print(f"‚ùå B≈ÇƒÖd przetwarzania {img_path}: {e}")
                results.append({'error': str(e), 'path': str(img_path)})
        
        # Podsumowanie
        anomaly_count = sum(1 for r in results if r.get('has_anomaly', False))
        print(f"\nüìà Podsumowanie przetwarzania partii:")
        print(f"   Przetworzono: {len(results)} obraz√≥w")
        print(f"   Z anomaliami: {anomaly_count}")
        print(f"   Bez anomalii: {len(results) - anomaly_count}")
        
        return results


# Funkcja pomocnicza do szybkiego u≈ºycia
def quick_detect(image_path: str, reference_dir: str = 'data/czyste',
                output_dir: str = 'anomaly_reports') -> Dict:
    """
    Szybka detekcja anomalii dla pojedynczego obrazu
    
    Args:
        image_path: ≈öcie≈ºka do obrazu
        reference_dir: Katalog z obrazami wzorcowymi
        output_dir: Katalog do zapisywania raport√≥w
        
    Returns:
        Wyniki detekcji
    """
    system = RTGAnomalySystem(reference_dir, output_dir)
    return system.process_image(image_path)


if __name__ == "__main__":
    # Przyk≈Çad u≈ºycia
    print("=" * 80)
    print("üî¨ System Detekcji Anomalii RTG")
    print("=" * 80)
    
    # Inicjalizuj system
    system = RTGAnomalySystem(
        reference_dir='data/czyste',
        output_dir='anomaly_reports'
    )
    
    # Testuj na obrazach z anomaliami
    test_dir = 'data/brudne'
    if os.path.exists(test_dir):
        results = system.batch_process(test_dir, pattern='*.bmp')
        
        # Wy≈õwietl podsumowanie
        print("\n" + "=" * 80)
        print("üìä SZCZEG√ì≈ÅOWE WYNIKI")
        print("=" * 80)
        for i, result in enumerate(results, 1):
            if 'error' not in result:
                print(f"\n{i}. {'üî¥ ANOMALIA' if result['has_anomaly'] else 'üü¢ CZYSTE'}")
                print(f"   Wykryto: {result['anomaly_count']} anomalii")
                print(f"   Podobie≈Ñstwo do wzorca: {result['similarity']:.2%}")
                if result.get('ssim_score'):
                    print(f"   SSIM: {result['ssim_score']:.4f}")
    else:
        print(f"‚ö†Ô∏è Katalog testowy nie istnieje: {test_dir}")
        print("U≈ºyj: python anomaly_detector.py lub quick_detect('path/to/image.bmp')")
